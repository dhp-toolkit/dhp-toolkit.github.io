{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0229ad75-f5c7-4ebf-bf33-e036e7036b5d",
   "metadata": {},
   "source": [
    "# Trucial Coast Towns: Building a Historical Gazetteer Dataset with GeoNames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8776632-2935-4248-bc98-9612f31cbc18",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "This tutorial assumes a basic understanding of how to work with Jupyter Notebook. We strongly recommend that you take the `Getting Started with Jupyter Notebook` tutorial before taking this tutorial.\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\"Gazetteers\" are structured lists of place names with information about their locations, variants, and historical context. In this tutorial, we will create a small dataset of historical places from the Trucial Coast (pre-UAE region) and enrich it using the GeoNames API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e90fe-98c3-4838-ab76-eae0784fd694",
   "metadata": {},
   "source": [
    "## 2. Objective\n",
    "We will:\n",
    "- Start from a CSV file containing a few historical town names\n",
    "- Use the GeoNames API to retrieve coordinates and metadata\n",
    "- Save the enriched dataset to a new CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa022-903f-46e8-970c-33aa23d70bf1",
   "metadata": {},
   "source": [
    "## 3. Setup: Install Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675abdf-27a8-45ea-8f1c-7a19fdf64464",
   "metadata": {},
   "source": [
    "We’ll be using the `pandas` and `requests` libraries in this tutorial. You can install them by running the following command.\n",
    "\n",
    "> **Note:** These libraries might already be installed in your environment.\n",
    "In that case, running the command will display: `Requirement already satisfied`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8637f1c-3b71-4b09-bd0e-d40bec626c05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9bf6a-8d88-4b3d-ab20-28bb87bbd64f",
   "metadata": {},
   "source": [
    "## 4. Load the Input CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad59ea6-69a1-4746-b2d0-7887aaa2cca0",
   "metadata": {},
   "source": [
    "Your input file should be named `trucial_towns.csv` and have at least the following column:\n",
    "- `name`: historical place name\n",
    "\n",
    "Aditional columns (optional but recommended):\n",
    "- `type`: A description of the kind of place — e.g., fort, settlement, port, etc.\n",
    "- `source`: A note about where the name came from — e.g., a historical map, archive, or article\n",
    "\n",
    "Columns `source, type` won’t be used in the GeoNames query itself, but they are useful for organizing, filtering, or analyzing your results later.\n",
    "\n",
    "Example row:\n",
    "```\n",
    "Ras Al Khaimah,\tport, Lorimer Gazetteer\n",
    "```\n",
    "📌 Note: You do not need to include a country code to make a query. In that case, the GeoNames API will search globally using only the place name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8ed45-1481-4058-90f1-e6e43fa73f1c",
   "metadata": {},
   "source": [
    "**Load the CSV:**\n",
    "\n",
    "Make sure to save `trucial_towns.csv` in the same folder as this notebook file (.ipynb) so it can be loaded correctly.\n",
    "\n",
    "The following code imports the `pandas` library and then loads the `trucial_towns.csv` file into a DataFrame called `df`. Finally, it displays the first five rows of the DataFrame to give you a preview of the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb16ad7b-a158-47e6-9130-0070facd74cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>type</th>\n",
       "      <th>notes</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ras Al Khaimah</td>\n",
       "      <td>AE</td>\n",
       "      <td>port</td>\n",
       "      <td>Base of Qawasim naval power in the 19th century</td>\n",
       "      <td>Lorimer, Gazetteer of the Persian Gulf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sharjah</td>\n",
       "      <td>AE</td>\n",
       "      <td>port</td>\n",
       "      <td>Major settlement on the Trucial Coast</td>\n",
       "      <td>Lorimer, Gazetteer of the Persian Gulf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm Al Quwain</td>\n",
       "      <td>AE</td>\n",
       "      <td>town</td>\n",
       "      <td>Historically under Al Ali rule</td>\n",
       "      <td>Lorimer, Gazetteer of the Persian Gulf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujairah</td>\n",
       "      <td>AE</td>\n",
       "      <td>town</td>\n",
       "      <td>Political independence recognized in early 20t...</td>\n",
       "      <td>UAE National Archives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dibba</td>\n",
       "      <td>AE</td>\n",
       "      <td>coastal town</td>\n",
       "      <td>Split among three rulers, major trade point</td>\n",
       "      <td>Arabian Gulf Studies, vol. 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name country_code          type  \\\n",
       "0  Ras Al Khaimah           AE          port   \n",
       "1         Sharjah           AE          port   \n",
       "2   Umm Al Quwain           AE          town   \n",
       "3        Fujairah           AE          town   \n",
       "4           Dibba           AE  coastal town   \n",
       "\n",
       "                                               notes  \\\n",
       "0    Base of Qawasim naval power in the 19th century   \n",
       "1              Major settlement on the Trucial Coast   \n",
       "2                     Historically under Al Ali rule   \n",
       "3  Political independence recognized in early 20t...   \n",
       "4        Split among three rulers, major trade point   \n",
       "\n",
       "                                   source  \n",
       "0  Lorimer, Gazetteer of the Persian Gulf  \n",
       "1  Lorimer, Gazetteer of the Persian Gulf  \n",
       "2  Lorimer, Gazetteer of the Persian Gulf  \n",
       "3                   UAE National Archives  \n",
       "4            Arabian Gulf Studies, vol. 2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load input CSV\n",
    "input_file = \"trucial_towns.csv\"  # Make sure this file is in the same folder as your notebook\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Display the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc89054-220a-4dd3-95a2-45f86462f3de",
   "metadata": {},
   "source": [
    "## 5. Define the GeoNames Query Function\n",
    "We will use the free GeoNames API to retrieve information for each town. You must register at [https://www.geonames.org/login](https://www.geonames.org/login) and get a username.\n",
    "\n",
    "To enrich the dataset, the tutorial leverages the free GeoNames API. Before proceeding, you need to register on the GeoNames website [https://www.geonames.org/login](https://www.geonames.org/login) to obtain a username.\n",
    "\n",
    "The `query_geonames` function is designed to send a request to the GeoNames API using a given place name. It processes the API's JSON response and extracts relevant information such as latitude, longitude, GeoNames ID, feature class, feature code, and filtered alternate names. The function includes logic to filter out irrelevant alternate names, such as URLs, airport codes (IATA, ICAO, FAAC), postal codes, Wikidata IDs, and short, all-caps codes.\n",
    "\n",
    "The following code defines the `query_geonames` function. Remember to replace \"geonames_username\" with your actual GeoNames username.\n",
    "\n",
    "This function constructs the API request, sends it, and then parses the JSON response to extract and return the desired geographic data and a semicolon-separated string of filtered alternate names. Error handling for requests exceptions is also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9707b39-b1ad-43c4-9c45-5695087393bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # For making HTTP requests to web services.\n",
    "import time     # For pausing execution to avoid hitting API rate limits.\n",
    "\n",
    "GEONAMES_USERNAME = \"yourGeonamesUsername\"  # CHANGE THIS with your GeoNames username\n",
    "\n",
    "def query_geonames(place_name): # Function to query the GeoNames API for a given place name.\n",
    "    base_url = \"http://api.geonames.org/searchJSON\" # Base URL for GeoNames search API.\n",
    "    params = {\n",
    "        'q': place_name,    # Query parameter: the place name to search.\n",
    "        'maxRows': 1,       # Limit results to the top 1 match.\n",
    "        'username': GEONAMES_USERNAME, # Your GeoNames username.\n",
    "        'style': 'FULL'     # Request full details in the response.\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params) # Send GET request.\n",
    "        response.raise_for_status()                     # Raise an exception for bad status codes (4xx or 5xx).\n",
    "        \n",
    "        print(f\"Querying: {place_name}\")               # Debug print: shows current query.\n",
    "        print(f\"Status Code: {response.status_code}\") # Debug print: shows HTTP status.\n",
    "        \n",
    "        results = response.json()                       # Parse JSON response into a Python dictionary.\n",
    "        # print(f\"Response JSON: {results}\")             # Debug print: shows full API response.\n",
    "        geonames_data = results.get('geonames', [])     # Extract 'geonames' list, default to empty list if not found.\n",
    "        \n",
    "        if geonames_data:\n",
    "            top = geonames_data[0]                      # Get the first (and only) result.\n",
    "            \n",
    "            filtered_alt_names = []                     # Initialize list for cleaned alternate names.\n",
    "            if 'alternateNames' in top:\n",
    "                for alt_obj in top['alternateNames']:\n",
    "                    name = alt_obj.get('name', '')      # Get alternate name.\n",
    "                    lang = alt_obj.get('lang', '')      # Get language code.\n",
    "\n",
    "                    # Filter rules for alternate names:\n",
    "                    if name.startswith('http'): continue          # Exclude URLs.\n",
    "                    if lang in ['iata', 'icao', 'faac', 'post', 'wkdt']: continue # Exclude specific codes.\n",
    "                    if len(name) <= 5 and name.isupper(): continue # Exclude short, all-caps codes.\n",
    "                    if name.startswith('Q') and name[1:].isdigit(): continue # Exclude Wikidata Q-codes.\n",
    "\n",
    "                    filtered_alt_names.append(name)     # Add valid alternate name.\n",
    "            \n",
    "            unique_alt_names = list(dict.fromkeys(filtered_alt_names)) # Remove duplicates while preserving order.\n",
    "            alt_names_str = \"; \".join(unique_alt_names) # Join unique names with semicolon.\n",
    "            \n",
    "            return (top.get('lat'),                     # Return latitude.\n",
    "                    top.get('lng'),                     # Return longitude.\n",
    "                    top.get('geonameId'),               # Return GeoNames ID.\n",
    "                    top.get('fcl'),                     # Return feature class.\n",
    "                    top.get('fcode'),                   # Return feature code.\n",
    "                    alt_names_str)                      # Return filtered alternate names string.\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying for '{place_name}': {e}\") # Print error message for request failures.\n",
    "        \n",
    "    return '', '', '', '', '', '' # Return empty strings on error or no results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68921db9-6b20-4f95-90e2-d2cc4c429664",
   "metadata": {},
   "source": [
    "## 6. Enrich the Dataset\n",
    "\n",
    "This section iterates through each row of the loaded dataset (`df`). For each historical place name, it calls the `query_geonames()` function to fetch relevant geographical data from the GeoNames API. \n",
    "\n",
    "The retrieved data, including latitude, longitude, GeoNames ID, feature class, feature code, and alternate names, is then added as new columns to the DataFrame. \n",
    "\n",
    "A one-second pause (`time.sleep(1)`) is incorporated between API requests to prevent exceeding GeoNames' rate limits. \n",
    "After processing all entries, the updated DataFrame with the newly added information is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "020d4a2c-d1d9-4724-b8e5-be0dad5f18a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying: Ras Al Khaimah\n",
      "Status Code: 200\n",
      "Querying: Sharjah\n",
      "Status Code: 200\n",
      "Querying: Umm Al Quwain\n",
      "Status Code: 200\n",
      "Querying: Fujairah\n",
      "Status Code: 200\n",
      "Querying: Dibba\n",
      "Status Code: 200\n",
      "             name country_code          type  \\\n",
      "0  Ras Al Khaimah           AE          port   \n",
      "1         Sharjah           AE          port   \n",
      "2   Umm Al Quwain           AE          town   \n",
      "3        Fujairah           AE          town   \n",
      "4           Dibba           AE  coastal town   \n",
      "\n",
      "                                               notes  \\\n",
      "0    Base of Qawasim naval power in the 19th century   \n",
      "1              Major settlement on the Trucial Coast   \n",
      "2                     Historically under Al Ali rule   \n",
      "3  Political independence recognized in early 20t...   \n",
      "4        Split among three rulers, major trade point   \n",
      "\n",
      "                                   source  latitude longitude geonames_id  \\\n",
      "0  Lorimer, Gazetteer of the Persian Gulf  25.78953   55.9432      291074   \n",
      "1  Lorimer, Gazetteer of the Persian Gulf  25.33737  55.41206      292672   \n",
      "2  Lorimer, Gazetteer of the Persian Gulf  25.56473  55.55517      290594   \n",
      "3                   UAE National Archives  25.11641  56.34141      292878   \n",
      "4            Arabian Gulf Studies, vol. 2  25.61955  56.27291      292239   \n",
      "\n",
      "  feature_class feature_code  \\\n",
      "0             P         PPLA   \n",
      "1             P         PPLA   \n",
      "2             P         PPLA   \n",
      "3             P         PPLA   \n",
      "4             P          PPL   \n",
      "\n",
      "                                     alternate_names  \n",
      "0  رأس الخيمة; Ra’s al-Chaima; Ras al-Khaimah; Ra...  \n",
      "1  إمارة الشارقة; Şarja; Шарджа; Charjah; Xarjah;...  \n",
      "2  أم القيوين; Umm al Qaywayn; Umm al-Quwain; Oum...  \n",
      "3  الفجيرة; Фуджейра; Fujairah; Fudschaira; Fuĵaj...  \n",
      "4                      Dibba Al-Hisn; Дибба Аль-Хисн  \n"
     ]
    }
   ],
   "source": [
    "df['latitude'] = ''\n",
    "df['longitude'] = ''\n",
    "df['geonames_id'] = ''\n",
    "df['feature_class'] = ''\n",
    "df['feature_code'] = ''\n",
    "df['alternate_names'] = ''\n",
    "\n",
    "# Query each place\n",
    "for idx, row in df.iterrows():\n",
    "    # The function now returns the alternate names string directly\n",
    "    lat, lon, gid, fcl, fcode, alt_names = query_geonames(row['name']) \n",
    "    \n",
    "    df.at[idx, 'latitude'] = lat\n",
    "    df.at[idx, 'longitude'] = lon\n",
    "    df.at[idx, 'geonames_id'] = gid\n",
    "    df.at[idx, 'feature_class'] = fcl\n",
    "    df.at[idx, 'feature_code'] = fcode\n",
    "    df.at[idx, 'alternate_names'] = alt_names # Populate the new column\n",
    "    \n",
    "    time.sleep(1)  # Pause to avoid rate limits\n",
    "\n",
    "# Show the first five entries of the table\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4fe17c-c05e-4b3f-8388-1c05ccafd01d",
   "metadata": {},
   "source": [
    "## 7. Save the Result into a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c78a67-cca6-4a45-b81c-bb767a5897eb",
   "metadata": {},
   "source": [
    "After the dataset has been enriched with information from GeoNames, the next step is to save the updated DataFrame to a new CSV file. This ensures that the retrieved data is persistently stored and can be used for further analysis or visualization.\n",
    "\n",
    "The following code block saves the df DataFrame to a new CSV file named `trucial_towns_enriched.csv`. \n",
    "The `index=False` argument prevents pandas from writing the DataFrame index as a column in the CSV file. \n",
    "A confirmation message is then printed to indicate that the file has been saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb10514a-05c2-4490-afaf-b0ad38369a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved enriched dataset to trucial_towns_enriched.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"trucial_towns_enriched.csv\"\n",
    "df.to_csv(output_file, index=False) # Save the output as a csv file\n",
    "print(f\"Saved enriched dataset to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827a5d2-8425-40d1-9532-b5116c74255c",
   "metadata": {},
   "source": [
    "## 8. Querying by Country, Feature Class, and Feature Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab29b8-6f5a-4fa7-92fd-c4421c276f55",
   "metadata": {},
   "source": [
    "Sometimes, you might want to find specific types of geographical features within a particular country, rather than searching for a named place globally. The GeoNames API allows you to refine your search using parameters like \n",
    "- `country` (two-letter ISO country code)\n",
    "- `featureClass` (a broad category like 'H' for hydrographic features or 'P' for populated places)\n",
    "- `featureCode` (a more specific type within a feature class, like 'RVR' for river or 'LAKE' for lake).\n",
    "\n",
    "You can get the list of featureCodes that belong to each featureClass [here](https://www.geonames.org/export/codes.html).\n",
    "\n",
    "This section demonstrates how to query for all hydrographic features (rivers, lakes, etc.) within a specific country (e.g., Turkey) and then save these results to a CSV file.\n",
    "\n",
    "First, let's define a new function `query_geonames_by_criteria` that takes `country_code`, `feature_class`, and an optional `feature_code` as arguments. This function will fetch results based on these criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64b7ac90-b3d2-41f2-b528-fd11ce16867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying Hydrographic Features in Turkey ---\n",
      "Querying GeoNames for features in TR (Class: H, Code: Any)...\n",
      "Status Code: 200\n",
      "Found 1000 features.\n",
      "  Sample 1: Name: Lake Van, Code: LK, Lat: 38.62457, Lng: 42.90604\n",
      "  Sample 2: Name: Bosporus, Code: STRT, Lat: 41.10164, Lng: 29.06097\n",
      "  Sample 3: Name: Lake Tuz, Code: LK, Lat: 38.72044, Lng: 33.38254\n",
      "  Sample 4: Name: Aegean Sea, Code: SEA, Lat: 39, Lng: 25\n",
      "  Sample 5: Name: Lake İznik, Code: LK, Lat: 40.43361, Lng: 29.51861\n",
      "\n",
      "--- Querying Rivers (RVR) in Turkey ---\n",
      "Querying GeoNames for features in TR (Class: H, Code: LK)...\n",
      "Status Code: 200\n",
      "Found 257 features.\n",
      "  Sample 1: Name: Lake Van, Code: LK, Lat: 38.62457, Lng: 42.90604\n",
      "  Sample 2: Name: Lake Tuz, Code: LK, Lat: 38.72044, Lng: 33.38254\n",
      "  Sample 3: Name: Kartsakhi Lake, Code: LK, Lat: 41.20741, Lng: 43.2091\n",
      "  Sample 4: Name: Lake İznik, Code: LK, Lat: 40.43361, Lng: 29.51861\n",
      "  Sample 5: Name: Abant Gölü, Code: LK, Lat: 40.605, Lng: 31.27972\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd # Import pandas to work with DataFrames and save to CSV\n",
    "\n",
    "GEONAMES_USERNAME = \"yourGeonamesUsername\"  # Replace with your actual GeoNames username\n",
    "\n",
    "def query_geonames_by_criteria(country_code, feature_class, feature_code=None, max_rows=1000):\n",
    "    # This function queries GeoNames for features based on country, feature class, and optional feature code\n",
    "    url = \"http://api.geonames.org/searchJSON\"\n",
    "    params = {\n",
    "        'country': country_code,     # ISO 2-letter country code (e.g., 'TR' for Turkey)\n",
    "        'featureClass': feature_class, # Feature Class (e.g., 'H' for hydrographic, 'P' for populated place)\n",
    "        'maxRows': max_rows,         # Maximum number of results to retrieve (up to 1000 for free account)\n",
    "        'username': GEONAMES_USERNAME\n",
    "    }\n",
    "    \n",
    "    if feature_code:\n",
    "        params['featureCode'] = feature_code # Add featureCode to parameters if provided.\n",
    "\n",
    "    print(f\"Querying GeoNames for features in {country_code} (Class: {feature_class}, Code: {feature_code if feature_code else 'Any'})...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params) # Send GET request\n",
    "        response.raise_for_status() # Raise an exception for HTTP errors\n",
    "        \n",
    "        print(f\"Status Code: {response.status_code}\") # Print HTTP status\n",
    "        data = response.json() # Parse JSON response\n",
    "        results = data.get('geonames', []) # Extract 'geonames' list\n",
    "        \n",
    "        print(f\"Found {len(results)} features.\") # Print number of results\n",
    "        \n",
    "        # Optionally print a sample of the results\n",
    "        for i, place in enumerate(results[:5]):\n",
    "            print(f\"  Sample {i+1}: Name: {place.get('name')}, Code: {place.get('fcode')}, Lat: {place.get('lat')}, Lng: {place.get('lng')}\")\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    except requests.exceptions.RequestException as e: # Catch errors as exceptions\n",
    "        print(f\"Error querying GeoNames: {e}\") # Print error message\n",
    "        return []\n",
    "\n",
    "# Example Usage: Query for hydrographic features in Turkey\n",
    "print(\"\\n--- Querying Hydrographic Features in Turkey ---\")\n",
    "tr_hydro_features = query_geonames_by_criteria(country_code='TR', feature_class='H')\n",
    "\n",
    "# Example Usage: Query for specific feature code - Rivers (RVR) in Turkey\n",
    "print(\"\\n--- Querying Rivers (RVR) in Turkey ---\")\n",
    "tr_lakes= query_geonames_by_criteria(country_code='TR', feature_class='H', feature_code='LK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193df0e-0592-4735-9c40-7ddb2916908a",
   "metadata": {},
   "source": [
    "Now that we have functions to query based on specific criteria, let's save the results into a CSV file for further use. We'll convert the list of dictionaries returned by the function into a Pandas DataFrame and then save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82ea0330-9c70-4518-be5a-bfd262eb33d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 1000 hydrographic features from Turkey to tr_hydrographic_features.csv with specified columns.\n",
      "Saved 257 rivers from Turkey to tr_rivers.csv with specified columns.\n"
     ]
    }
   ],
   "source": [
    "# Define the desired column order\n",
    "desired_columns = ['name', 'lat', 'lng', 'countryName', 'countryCode', 'fcl', 'fclName', 'fcode', 'fcodeName', 'adminName1']\n",
    "\n",
    "# Process and save hydrographic features for Turkey\n",
    "if tr_hydro_features:\n",
    "    df_tr_hydro = pd.DataFrame(tr_hydro_features) # Convert results to DataFrame\n",
    "    df_tr_hydro_selected = df_tr_hydro[desired_columns]     # Select and reorder columns\n",
    "    output_filename_hydro_tr = \"tr_hydrographic_features.csv\" # Define output filename\n",
    "    df_tr_hydro_selected.to_csv(output_filename_hydro_tr, index=False) # Save to CSV, no index\n",
    "    print(f\"\\nSaved {len(tr_hydro_features)} hydrographic features from Turkey to {output_filename_hydro_tr} with specified columns.\")\n",
    "\n",
    "# Process and save rivers for Turkey\n",
    "if tr_rivers:\n",
    "    df_tr_rivers = pd.DataFrame(tr_rivers)\n",
    "    df_tr_rivers_selected = df_tr_rivers[desired_columns]\n",
    "    output_filename_rivers_tr = \"tr_rivers.csv\"\n",
    "    df_tr_rivers_selected.to_csv(output_filename_rivers_tr, index=False)\n",
    "    print(f\"Saved {len(tr_rivers)} rivers from Turkey to {output_filename_rivers_tr} with specified columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ef9e8-014e-4d23-ad64-56c320421c6f",
   "metadata": {},
   "source": [
    "## 9. What's Next?\n",
    "Now that you have coordinates and metadata, you can:\n",
    "- Import into QGIS or Google My Maps for visualization\n",
    "- Align with the World Historical Gazetteer (WHG)\n",
    "- Add temporal information and submit your dataset to WHG for educational use\n",
    "\n",
    "You can also extend this notebook to:\n",
    "- Query for multiple alternate names\n",
    "- Visualize the towns using Python libraries like `folium` or `plotly`\n",
    "- Compare coverage with Wikidata or WHG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02ff36-c9ba-4ec7-850a-b4133e86cdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
